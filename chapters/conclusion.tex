\chapter{Conclusion and Future Work}
\label{ch:conclusion}

The work presented so far comprises the first attempt toward building a more space-efficient version of the Tentris triple store. So far, the goal was fulfilled to an acceptable level where a compressed version of hypertrie was actually implemented. It brings good levels of compression while at the same time maintain the mapping from tensor operations to hypertrie semantic. Based on the evaluation phase, the design of the compressed hypertrie should be reconsidered to come up with a more efficient version that can process the queries at least at the same speed as the original hypertrie does.\\

Back to the evaluation results in chapter 5, benchmarks against SWDF data set scored the worst results. The used SWDF data set has a limited number of predicates (185) and a number of objects three times bigger than the number of subjects. This leads us to consider how the compressed hypertrie is holding such data set looks like. Nearly zero compressed paths are stored in the root node for predicate positions, and a small number of compressed paths are stored in subject positions, much smaller than the amount of collapsed three paths on the object positions. As queries may incorporate fixing the object position with a key part, the evaluation of the query's triple pattern will result in handling a significant amount of virtual nodes operations. Extracting representation of hypertrie nodes in virtual nodes is time-consuming with many casting operations and pointer de-referencing operations.

\paragraph{Future Work}
As a next step, it is possible to build on top of the space reduction approach presented in this thesis to tackle the performance overhead challenge. That can be achieved by either adopting a new space reduction approach similar to the ones presented in chapter 3, or rethink the concrete design of hypertrie on the node structure level or the behavior level.